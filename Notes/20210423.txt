Reinforcement Learning
----------------------
Natural Language Processing
---------------------------
Homework 5
----------
Value Iteration for Markov Decision Process
Question 1
----------
s - {ML United under-15s, NLP Albion, Computer Vision Wanderers}
V*(NLP Albion|ML United under-15s) = 0.6*10000 + 0.4*70000 = 34000
V*(Computer Vision Wanderers|ML United under-15s) = 37000

U = psi*S^2 + eta

MDP
---
A B C D
pi*(A,up) = 1 + 0.75*1 + 0.75*0.75*10
pi*(A,down) = 0

pi*(B,up) = 1 + 0.75*10 
pi*(B,down) = 1

pi*(C,up) = 10
pi*(C,down) = 1 + 0.75*1

pi*(D,up) = 0
pi*(D,down) = 10 + 0.75*1 + 0.75*0.75*1

V(i+1)*(s) = sum(s') T(s,a,s')(R(s,a,s') + gamma*(V(i)(s')))
V(i+1)*(s) = sum(s') R(s,a,s') + gamma*V(i)(s')

V*(s) = [V*(A) V*(B) V*(C) V*(D)]
V0*(s) = [0 0 0 0]
V1*(s) = [1+0.75*0 (1+0.75*0 + 1+0.75*0) (10+0.75*0 + 1+0.75*0) (10+0.75*0)]

Tab2
----
Q-Value Iteration
-----------------

                  0   1   2   3   4   5
                  ---------------------
T(s,a,s')[M,C] = [1   0   0   0   0   0  ]0
                 [1   0   0   0   0   0  ]1
                 [0   1   0   0   0   0  ]2
                 [0   0   1   0   0   0  ]3
                 [0   0   0   1   0   0  ]4
                 [0   0   0   0   1   0  ]5

                 [1   0   0   0   0   0  ]0
                 [0   0.3 0   0.7 0   0  ]1
                 [0   0   0.3 0   0.7 0  ]2
                 [0   0   0   0.3 0   0.7]3
                 [0   0   0   0   1   0  ]4
                 [0   0   0   0   0   1  ]5

                  0     1     2     3     4     5
                  -------------------------------
R(s,a,s')[M,C] = [0     1     1.260 1.442 1.587 1.710]0
                 [1     0.447 1     1.260 1.442 1.587]1
                 [1.260 1     0.408 1     1.260 1.442]2
                 [1.442 1.259 1     0.378 1     1.260]3
                 [1.587 1.442 1.260 1     0.354 1    ]4
                 [1.710 1.587 1.442 1.260 1     0.333]5

                 [0     1     1.260 1.442 1.587 1.710]0
                 [1     0.447 1     1.260 1.442 1.587]1
                 [1.260 1     0.408 1     1.260 1.442]2
                 [1.442 1.259 1     0.378 1     1.260]3
                 [1.587 1.442 1.260 1     0.354 1    ]4
                 [1.710 1.587 1.442 1.260 1     0.333]5

gamma = 0.6

Q(i+1)(s,a) = sum(s') T(s,a,s')*(R(s,a,s') + gamma*max(a') Q(i)(s',a'))
Q0(s,a) = [0 0 0 0 0 0]
          [0 0 0 0 0 0]

      0     1     2     3     4    5
Q1 = [0     0     0     0     0    0]M
     [0     0     0     0     0    0]C

Tab 3
-----
Q-value Iteration
-----------------

using the following index for states

8  9  10 11
4  5  6  7 
0  1  2  3 

        0     1     2     3     4     5     6     7     8     9     10    11
Q0 = [[-0.04  0.   -0.04 -1.04 -0.04  0.   -0.04  0.    0.    0.    0.    0.  ] up
      [ 0.    0.    0.    0.   -0.04  0.   -0.04  0.   -0.04  0.   -0.04  0.  ] down
      [ 0.   -0.04 -0.04 -0.04  0.    0.    0.    0.    0.   -0.04 -0.04  0.  ] left
      [-0.04 -0.04 -0.04  0.    0.    0.   -1.04  0.   -0.04 -0.04  0.96  0.  ]]right

