Colloborative filtering
-----------------------
Matrix Factorization
--------------------
U = [User 1, User 2, User 3]
V = [Movie 1, Movie 2]
Alternating Minimalization
--------------------------
Y = [1 8 ?]
    [2 ? 5]
V = [4 
    2 
    1]
U = [u1 
    u2]
U*V_T = [4u1 2u1 u1]
        [4u2 2u2 u2]
U*V_T + lambda*|u|^2/2 
(1-4u1)^2/2 + (8-2u1)^2/2 + lambda*u1^2/2
(2-4u2)^2/2 + (5- u2)^2/2 + lambda*u2^2/2

min = 0
(1-4u1)(-4) + (8-2u1)(-2) + lambda*u1 = (-4-16) + (16+4+lambda)u1
(2-4u2)(-4) + (5- u2)(-1) + lambda*u2 = (-8- 5) + (16+1+lambda)u2

u1 = 20/(20+lambda)
u2 = 13/(17+lambda)

Homework 2
----------
Alternating Minimalization
--------------------------

Objective Function
J(U,V) = 0.5*sum(Y(a,i) - [U(a,i)V_T(a,i)])^2 + lambda*0.5*sum(sum(U(a,j)^2)) + lambda*0.5*(sum(sum(V(i,j)^2)))

Y = [5 ? 7]
    [? 2 ?]
    [4 ? ?]
    [? 3 6]
k=lambda=1
J(U,V) = 0.5*sum(Y(a,i) - [U(a,i)V_T(a,i)])^2 + 0.5*sum(U(a)^2) + 0.5sum(V(i)^2)
U(0) = [6
        0
        3
        6]
V(0) = [4
        2
        1]
X(0)= [24 12 6]
      [ 0  0 0]
      [12  6 3]
      [24 12 6]
Squared Error Term
------------------
sum(0.5*(Y(0-X(0))^2) = [0.5(5-24)^2 + 0.5(7-6)^2] +
                        [0.5(2- 0)^2] +
                        [0.5(4-12)^2] +
                        [0.5(3-12)^2 + 0.5(6-6)^2]
                      = [181] +
                        [  2] +
                        [ 32] +
                        [40.5]
                      = 255.5
Regularization Term
-------------------
sum(0.5*(U(0)^2) + 0.5*(V(0)^2)) = [13] + [ 8] +
                                   [ 0] + [ 2] +
                                   [4.5] + [0.5] +
                                   [13] 
                                 = 51
First Update
------------
U(1)*V_T = [4u1 2u1 1u1]
           [4u2 2u2 1u2]
           [4u3 2u3 1u3]
           [4u4 2u4 1u4] 

(5-4u1)(-4) + (7-u1)(-1) + u1 = -27 + 18u1
(2-2u2)(-2)              + u2 =  -4 +  5u2
(4-4u3)(-4)              + u3 = -16 + 17u3
(3-2u4)(-2) + (6-u4)(-1) + u4 = -12 +  6u4

U(1) = [3/2]
       [4/5]
       [16/17]
       [12/6]

Feature Vector Transformation
-----------------------------

[z1] = [A11 A12 A13 A14 A15 A16]*[x1 
[z2]   [A21 A22 A23 A24 A25 A26]  x2 
                                  x3 
                                  x4 
                                  x5 
                                  x6]
A = [1/6 1/6 1/6 1/6 1/6 1/6]                        
    [1/6 1/6 1/6 -1/6 -1/6 -1/6]

Linear Classifier -Feature Vector - Data Vector Transformation
0z1(z1) +0z2(z2)
0z1(x1+x2+x3+x4+x5+x6)/6 + 0z2(x1+x2+x3-x4-x5-x6)/6

0z - (2,1)
0x - (6,1)
A  - (2,6)

0x = A_T*0z

Kernels
-------
Polynomial Kernel
((x1,x2)(q1,q2) + 1)^2 = ((x1,x2)(q1,q2))^2 + 1 + 2*(x1,x2)(q1,q2) 
                       = (x1q1 + x2q2)^2 + 1 + 2(x1q1 + x2q2)
                       = (x1q1)^2 + (x2q2)^2 + 1 + 2x1q1x2q2 + 2x1q1 + 2x2q2

2xq + (xq)^2 + 1 = 2(x1,x2)(q1,q2) + ((x1,x2)(q1,q2))^2 + 1
                = 2x1q1 + 2x2q2 + x1^2q1^2 + 2x1x2q1q2 + x2^2q2^2 + 1
Vector form 
                = [sqrt(2)x1,sqrt(2)x2,x1^2,sqrt(2)x1x2,x2^2,1].[sqrt(2)q1,sqrt(2)q2,q1^2,sqrt(2)q1q2,q2^2,1]
                = 2x1q1 + 2x2q2 + x1^2q1^2 + 2x1x2q1q2 + x2^2q2^2 + 1 
                = (x1q1)^2 + (x2q2)^2 + 1 + 2x1q1x2q2 + 2x1q1 + 2x2q2

Homework 5
----------
Ridge regression
----------------
-3(bary - 0barx)(barx) + 2lambda*0
-3barybarx - 30barx^2 + 2lambda*0
-3barybarx - (3barx^2 - 2lambda)0
0 = -3barybarx/(3barx^2 - 2lambda)
(revisit)